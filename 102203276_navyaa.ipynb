{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DKO9MFYXptyo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, KFold\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yzkAmf7tqAAV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Creditcard_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YCI6xYPoqFVf"
      },
      "outputs": [],
      "source": [
        "# Oversampling minority class using SMOTE\n",
        "X1 = df.drop('Class', axis=1)\n",
        "y1 = df['Class']\n",
        "smote = SMOTE(random_state=40)\n",
        "X_smote, y_smote = smote.fit_resample(X1, y1)\n",
        "X = X_smote.values\n",
        "y = y_smote.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M8QVzp6AqOBQ"
      },
      "outputs": [],
      "source": [
        "# Define the five different machine learning models\n",
        "M1 = GaussianNB()\n",
        "M2 = LogisticRegression(random_state=40, solver='lbfgs', max_iter=100)\n",
        "M3 = KNeighborsClassifier()\n",
        "M4 = SVC(random_state=40)\n",
        "M5 = DecisionTreeClassifier(random_state=40)\n",
        "# Didnt chose Random forest as it was giving 1 accuracy with all sampling techniques and it was looking Invalid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZfEosWo5qbwo"
      },
      "outputs": [],
      "source": [
        "# Define the five different sampling techniques\n",
        "Sampling1 = 'Random Sampling'\n",
        "Sampling2 = 'Stratified Sampling'\n",
        "Sampling3 = 'Cluster Sampling'\n",
        "Sampling4 = 'OverSampling'\n",
        "Sampling5 = 'Undersampling'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pEwNLFm0r83N"
      },
      "outputs": [],
      "source": [
        "# Define a function to apply the different sampling techniques to the different machine learning models\n",
        "def apply_sampling(model, sampling_technique, X, y):\n",
        "    if sampling_technique == Sampling1:\n",
        "        train_index, test_index = train_test_split(range(X.shape[0]), test_size=0.60, random_state=101)\n",
        "        X_sampled, y_sampled = X[train_index], y[train_index]\n",
        "\n",
        "    elif sampling_technique == Sampling2:\n",
        "        sss = StratifiedShuffleSplit(n_splits=1, test_size=0.60, random_state=101)\n",
        "        train_index, test_index = next(sss.split(X, y))\n",
        "        X_sampled, y_sampled = X[train_index], y[train_index]\n",
        "\n",
        "    elif sampling_technique == Sampling3:\n",
        "        kf = KFold(n_splits=5, shuffle=True, random_state=101)\n",
        "        cluster_indices = []\n",
        "        for _, test_index in kf.split(X):\n",
        "            cluster_indices.append(test_index)\n",
        "        test_index = np.concatenate(cluster_indices)\n",
        "        X_sampled, y_sampled = X[test_index], y[test_index]\n",
        "\n",
        "    elif sampling_technique == Sampling4:\n",
        "        ros = RandomOverSampler(random_state=101)\n",
        "        X_sampled, y_sampled = ros.fit_resample(X, y)\n",
        "\n",
        "    elif sampling_technique == Sampling5:\n",
        "        rus = RandomUnderSampler(random_state=101)\n",
        "        X_sampled, y_sampled = rus.fit_resample(X, y)\n",
        "\n",
        "    # Split the sampled data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sampled, y_sampled, test_size=0.3, random_state=40)\n",
        "\n",
        "    # Fit the machine learning model on the training data and evaluate it on the testing data\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VTFEWZiFr-fW"
      },
      "outputs": [],
      "source": [
        "# Define the list of models and sampling techniques to evaluate\n",
        "models = [M1, M2, M3, M4, M5]\n",
        "sampling_techniques = [Sampling1, Sampling2, Sampling3, Sampling4, Sampling5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "id": "yEE0QWxKsBMA",
        "outputId": "867c9bc3-a45e-4f92-f0ab-7091e137c359"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\navya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\navya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\navya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\navya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\navya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Resultant Matrix is:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Sampling</th>\n",
              "      <th>Stratified Sampling</th>\n",
              "      <th>Cluster Sampling</th>\n",
              "      <th>OverSampling</th>\n",
              "      <th>Undersampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.765027</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.873362</td>\n",
              "      <td>0.812227</td>\n",
              "      <td>0.882096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.907104</td>\n",
              "      <td>0.896175</td>\n",
              "      <td>0.927948</td>\n",
              "      <td>0.910480</td>\n",
              "      <td>0.893013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K-Nearest Neighbours</th>\n",
              "      <td>0.775956</td>\n",
              "      <td>0.765027</td>\n",
              "      <td>0.842795</td>\n",
              "      <td>0.812227</td>\n",
              "      <td>0.814410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <td>0.693989</td>\n",
              "      <td>0.704918</td>\n",
              "      <td>0.676856</td>\n",
              "      <td>0.679039</td>\n",
              "      <td>0.661572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.989071</td>\n",
              "      <td>0.950820</td>\n",
              "      <td>0.984716</td>\n",
              "      <td>0.984716</td>\n",
              "      <td>0.975983</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Random Sampling  Stratified Sampling  \\\n",
              "Naive Bayes                    0.765027             0.836066   \n",
              "Logistic Regression            0.907104             0.896175   \n",
              "K-Nearest Neighbours           0.775956             0.765027   \n",
              "Support Vector Machine         0.693989             0.704918   \n",
              "Decision Tree                  0.989071             0.950820   \n",
              "\n",
              "                        Cluster Sampling  OverSampling  Undersampling  \n",
              "Naive Bayes                     0.873362      0.812227       0.882096  \n",
              "Logistic Regression             0.927948      0.910480       0.893013  \n",
              "K-Nearest Neighbours            0.842795      0.812227       0.814410  \n",
              "Support Vector Machine          0.676856      0.679039       0.661572  \n",
              "Decision Tree                   0.984716      0.984716       0.975983  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Accuracy achieved is  0.989071\n"
          ]
        }
      ],
      "source": [
        "# Evaluate each model with each sampling technique and store the results in a matrix\n",
        "results = np.zeros((len(models), len(sampling_techniques)))\n",
        "for i, model in enumerate(models):\n",
        "    for j, technique in enumerate(sampling_techniques):\n",
        "            accuracy = apply_sampling(model, technique, X, y)\n",
        "            results[i, j] = accuracy\n",
        "\n",
        "# Convert the results matrix to a pandas DataFrame with row and column names\n",
        "results_df = pd.DataFrame(results, index=['Naive Bayes', 'Logistic Regression', 'K-Nearest Neighbours', 'Support Vector Machine', 'Decision Tree'],\n",
        "                                     columns=[Sampling1, Sampling2, Sampling3, Sampling4, Sampling5])\n",
        "\n",
        "# Print the results DataFrame\n",
        "print('The Resultant Matrix is:\\n')\n",
        "display(results_df)\n",
        "print('Maximum Accuracy achieved is ',round(results_df.values.max(), 6))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
